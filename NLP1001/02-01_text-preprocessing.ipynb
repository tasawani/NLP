{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP - Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemma VS Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "porter_stemmer = PorterStemmer()\n",
    "wordnet_lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_lemma_porter(text):\n",
    "  print(f\"{'word':<12} \\t {'lemma':<12} \\t {'stem':<12}\")\n",
    "  print('-'*50)\n",
    "  for word in text:\n",
    "    print(f'{word:12} \\t {wordnet_lemma.lemmatize(word):12} \\t {porter_stemmer.stem(word):12}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word         \t lemma        \t stem        \n",
      "--------------------------------------------------\n",
      "fly          \t fly          \t fli         \n",
      "flies        \t fly          \t fli         \n",
      "flying       \t flying       \t fli         \n",
      "flew         \t flew         \t flew        \n",
      "flown        \t flown        \t flown       \n"
     ]
    }
   ],
   "source": [
    "word_list = ['fly', 'flies', 'flying', 'flew', 'flown']\n",
    "display_lemma_porter(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word         \t lemma        \t stem        \n",
      "--------------------------------------------------\n",
      "universe     \t universe     \t univers     \n",
      "university   \t university   \t univers     \n",
      "universal    \t universal    \t univers     \n"
     ]
    }
   ],
   "source": [
    "word_list = ['universe', 'university', 'universal']\n",
    "display_lemma_porter(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word         \t lemma        \t stem        \n",
      "--------------------------------------------------\n",
      "The          \t The          \t the         \n",
      "formatting   \t formatting   \t format      \n",
      "operations   \t operation    \t oper        \n",
      "described    \t described    \t describ     \n",
      "here         \t here         \t here        \n",
      "exhibit      \t exhibit      \t exhibit     \n",
      "a            \t a            \t a           \n",
      "variety      \t variety      \t varieti     \n",
      "of           \t of           \t of          \n",
      "quirks       \t quirk        \t quirk       \n",
      "the          \t the          \t the         \n",
      "lead         \t lead         \t lead        \n",
      "to           \t to           \t to          \n",
      "a            \t a            \t a           \n",
      "number       \t number       \t number      \n",
      "of           \t of           \t of          \n",
      "common       \t common       \t common      \n",
      "errors.      \t errors.      \t errors.     \n"
     ]
    }
   ],
   "source": [
    "word_list = \"The formatting operations described here exhibit a variety of quirks the lead to a number of common errors.\".split()\n",
    "display_lemma_porter(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    output = [i for i in text if i not in stopwords]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: ['Thailand', '(Thai:', 'ประเทศไทย),', 'known', 'formerly', 'as', 'Siam', 'and', 'officially', 'as', 'the', 'Kingdom', 'of', 'Thailand,', 'is', 'a', 'country', 'inSoutheast', 'Asia.']\n",
      "Remove stopword: ['Thailand', '(Thai:', 'ประเทศไทย),', 'known', 'formerly', 'Siam', 'officially', 'Kingdom', 'Thailand,', 'country', 'inSoutheast', 'Asia.']\n"
     ]
    }
   ],
   "source": [
    "text = 'Thailand (Thai: ประเทศไทย), known formerly as Siam and officially as the Kingdom of Thailand, is a country inSoutheast Asia.'.split()\n",
    "print('Original text:', text)\n",
    "print('Remove stopword:', remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dict = {'2moro':'tomorrow',\n",
    "             '2mrrw':'tomorrow',\n",
    "             '2morrow':'tomorrow', \n",
    "             '2mrw':'tomorrow',\n",
    "             'tomrw':'tomorrow',\n",
    "             'b4':'before',\n",
    "             'otw':'on the way',\n",
    "             ':)':'smile',\n",
    "             ';-)':'smile'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(text):\n",
    "    res = [norm_dict[w] if w in norm_dict else w for w in text]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tomorrow', 'tomorrow', 'tomorrow', 'tomorrow', 'tomorrow', 'before']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = ['2moro', '2mrrw', '2morrow', '2mrw', 'tomrw', 'b4']\n",
    "normalise(word_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_words(text):\n",
    "    \"\"\"Basic cleaning of texts.\"\"\"\n",
    "    # remove html markup\n",
    "    text = re.sub(\"(<.*?>)\",\"\",text)\n",
    "\n",
    "    # remove non-ascii and digits\n",
    "    text = re.sub(\"(\\\\W|\\\\d)\",\"\",text)\n",
    "\n",
    "    # remove whitespace\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_word</th>\n",
       "      <th>cleaned_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..trouble..</td>\n",
       "      <td>trouble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble&lt;</td>\n",
       "      <td>trouble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trouble!</td>\n",
       "      <td>trouble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;a&gt;trouble&lt;/a&gt;</td>\n",
       "      <td>trouble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.trouble</td>\n",
       "      <td>trouble</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         raw_word cleaned_word\n",
       "0     ..trouble..      trouble\n",
       "1        trouble<      trouble\n",
       "2        trouble!      trouble\n",
       "3  <a>trouble</a>      trouble\n",
       "4       1.trouble      trouble"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_words = [\"..trouble..\", \"trouble<\", \"trouble!\", \"<a>trouble</a>\", '1.trouble'] \n",
    "cleaned_words = [scrub_words(w) for w in raw_words] \n",
    "stemdf = pd.DataFrame({ 'raw_word' : raw_words, 'cleaned_word' : cleaned_words }) \n",
    "stemdf = stemdf[['raw_word', 'cleaned_word']] \n",
    "stemdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Enrichment / Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('plan.n.01'),\n",
       " Synset('program.n.02'),\n",
       " Synset('broadcast.n.02'),\n",
       " Synset('platform.n.02'),\n",
       " Synset('program.n.05'),\n",
       " Synset('course_of_study.n.01'),\n",
       " Synset('program.n.07'),\n",
       " Synset('program.n.08'),\n",
       " Synset('program.v.01'),\n",
       " Synset('program.v.02')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns = wordnet.synsets(\"program\")\n",
    "syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plan',\n",
       " 'program',\n",
       " 'broadcast',\n",
       " 'platform',\n",
       " 'program',\n",
       " 'course_of_study',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program',\n",
       " 'program']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.lemmas()[0].name() for s in syns]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "playground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
